### 基础函数

```python
type() #显示类型
help(...)#显示帮助
print(dir(...)) #显示可用函数
```



## 数据操作

读取、处理

~~~python
import pandas as pd
from mxnet import np

data = pd.read_csv(data_file)
print(data)
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2] #按照列切开
inputs = inputs.fillna(inputs.mean()) #填充
sum.argmax() #返回最大元素所在位置
data = data.drop(columns=sum.index[sum.argmax()]) #丢掉某些列
x = np.array(data) #转化为张量
~~~



张量操作

~~~python
A = np.arange(20).reshape(5, 4) #生成
A.shape #形状
sum_A = A.sum(axis=1, keepdims=True) #按行求和，保持阶数
np.dot(A,B) #点积
np.linalg.norm(A) #求范数
~~~



绘图

~~~python

import numpy as np
from d2l.torch import plot




x = np.arange(0, 3, 0.1)
plot(x, [x**3-1/x, 4*x-4], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])

~~~





![Figure_1](C:\Users\17744\Desktop\新建文件夹\Figure_1.png)



求梯度

~~~python
import torch

x = torch.arange(4.0)
x.requires_grad_(True)
y = 2 * torch.dot(x, x)
y.backward() #反向传播
x.grad

u = y.detach #创建复制
~~~

实例：绘制sin(x)及其导数图像

~~~python
from d2l import torch as d2l
x=torch.arange(0.,10.,0.1)
x.requires_grad_(True)
y=torch.sin(x)
y.sum().backward()
d2l.plot(x.detach(),[y.detach(),x.grad],'x','y',legend=['y','dy/dx'])
~~~

概率

~~~python
import torch
from torch.distributions import multinomial
from d2l import torch as d2l

fair_probs = torch.ones([6]) / 6
multinomial.Multinomial(1, fair_probs).sample() #依照fair_probs取样1次

'''
绘制频率图
'''

counts = multinomial.Multinomial(10, fair_probs).sample((500,))#对于500*1的二阶张量中每个元素，取样10次
cum_counts = counts.cumsum(dim=0)
estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)

d2l.set_figsize((6, 4.5))
for i in range(6):
    d2l.plt.plot(estimates[:, i].numpy(),
                 label=("P(die=" + str(i + 1) + ")")) #绘图
d2l.plt.axhline(y=0.167, color='black', linestyle='dashed')
d2l.plt.gca().set_xlabel('Groups of experiments')
d2l.plt.gca().set_ylabel('Estimated probability')
d2l.plt.legend();

~~~

## 线性回归

